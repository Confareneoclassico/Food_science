{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "from functools import lru_cache\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sobol_seq\n",
    "import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package requirements for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==0.21.2\n",
      "pandas==0.23.4\n",
      "numpy==1.11.3\n",
      "matplotlib==2.2.2\n"
     ]
    }
   ],
   "source": [
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            \n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "            \n",
    "        poorly_named_packages = {\n",
    "            \"PIL\": \"Pillow\",\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the initial dataset you'll be working on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SatelliteJuly = pd.read_excel('Data.xlsx',sheet_name='July_sat').drop([r for r in range(12,24)]).reset_index(drop=True)\n",
    "SatelliteJune = pd.read_excel('Data.xlsx',sheet_name='June_sat').drop([r for r in range(12,24)]).reset_index(drop=True)\n",
    "SatelliteMay = pd.read_excel('Data.xlsx',sheet_name='May_sat').drop([r for r in range(12,24)]).reset_index(drop=True)\n",
    "SatelliteApril = pd.read_excel('Data.xlsx',sheet_name='April_satellite').drop([r for r in range(12,\n",
    "                                                                                                24)]).reset_index(drop=True)\n",
    "Seed = pd.read_excel('Data.xlsx',sheet_name='Chem_comp_wheat',usecols=[1,2,3,4,5,6,7,8]).drop([r for r in range(12,\n",
    "                                                                                                24)]).reset_index(drop=True)\n",
    "Dough = pd.read_excel('Data.xlsx',sheet_name='Dough',usecols=[2,3]).drop([r for r in range(12,24)]).reset_index(drop=True)\n",
    "Bread = pd.read_excel('Data.xlsx',sheet_name='Bread',usecols=[2,3,4,5,6,9]).drop([r for r in range(12,24)]).reset_index(drop=True)\n",
    "Seed2 = Seed.copy()\n",
    "Seed2[['Prot sol acq','Prot nacl','Prot etoh', 'Prot ac ac']] = \\\n",
    "Seed[['Prot sol acq','Prot nacl','Prot etoh', 'Prot ac ac']].apply(lambda x: Seed.T.iloc[3].T * x/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD = [SatelliteApril,SatelliteMay,SatelliteJune,SatelliteJuly]\n",
    "\n",
    "SatelliteData = pd.concat(SD,axis=1,sort=False).dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Seed','Dough','Bread']\n",
    "db = [Seed,Dough,Bread]\n",
    "Fc = [(names[idb],c) for idb,d in enumerate(db) for c in d ]\n",
    "Features = pd.concat([Seed,Dough,Bread],axis=1)\n",
    "Features.columns = pd.MultiIndex.from_tuples(Fc,names=('Stage','Feature'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the Random-Forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = (sobol_seq.i4_sobol_generate(2,1000)*np.array([len(SatelliteData.columns),len(SatelliteData)])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=500,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_features = []\n",
    "R2_list = []\n",
    "l_predictions = []\n",
    "\n",
    "for s in seed:\n",
    "    regr.fit(SatelliteData.drop(SatelliteData.columns[s[0]],axis=1).drop(SatelliteData.index[s[1]],axis=0),\n",
    "             Features.drop(Features.index[s[1]],axis=0))\n",
    "\n",
    "    l_features.append(pd.Series(regr.feature_importances_,\n",
    "                                index=SatelliteData.columns.drop(SatelliteData.columns[s[0]])))\n",
    "    \n",
    "    R2_list.append(pd.Series(regr.score(SatelliteData.drop(SatelliteData.columns[s[0]],axis=1).drop(SatelliteData.index[s[1]],\n",
    "            axis=0),Features.drop(Features.index[s[1]],axis=0)),index=[s[1]]))\n",
    "    \n",
    "    l_predictions.append(pd.DataFrame(regr.predict(SatelliteData.drop(SatelliteData.columns[s[0]],\n",
    "                                                axis=1).iloc[s[1]].values.reshape(-1,1).T),index=[s[1]]))\n",
    "    \n",
    "df_features = pd.concat(l_features,axis=1,sort=True).T\n",
    "\n",
    "df_predictions = pd.concat(l_predictions).sort_index()\n",
    "df_predictions.columns = Features.columns\n",
    "\n",
    "R2_df = pd.concat(R2_list).sort_index()\n",
    "R2_metrics = R2_df.groupby(R2_df.index).mean().round(2)\n",
    "\n",
    "Err = np.abs(df_predictions.groupby(df_predictions.index).mean()-Features)/Features\n",
    "       \n",
    "Err2 = Err.applymap(lambda x: \"{0:.1f}%\".format(x*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mytable.tex', 'w') as tf:\n",
    "     tf.write(Err.round(2).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase the number of trees to 1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr2 = RandomForestRegressor(n_estimators=1_000,n_jobs=-1)\n",
    "\n",
    "l_features = []\n",
    "R2_list = []\n",
    "l_predictions = []\n",
    "\n",
    "for s in seed:\n",
    "    regr2.fit(SatelliteData.drop(SatelliteData.columns[s[0]],axis=1).drop(SatelliteData.index[s[1]],axis=0),\n",
    "             Features.drop(Features.index[s[1]],axis=0))\n",
    "\n",
    "    l_features.append(pd.Series(regr2.feature_importances_,\n",
    "                                index=SatelliteData.columns.drop(SatelliteData.columns[s[0]])))\n",
    "    \n",
    "    R2_list.append(pd.Series(regr2.score(SatelliteData.drop(SatelliteData.columns[s[0]],axis=1).drop(SatelliteData.index[s[1]],\n",
    "            axis=0),Features.drop(Features.index[s[1]],axis=0)),index=[s[1]]))\n",
    "    \n",
    "    l_predictions.append(pd.DataFrame(regr2.predict(SatelliteData.drop(SatelliteData.columns[s[0]],\n",
    "                                                axis=1).iloc[s[1]].values.reshape(-1,1).T),index=[s[1]]))\n",
    "    \n",
    "df_features = pd.concat(l_features,axis=1,sort=True).T\n",
    "\n",
    "df_predictions = pd.concat(l_predictions).sort_index()\n",
    "df_predictions.columns = Features.columns\n",
    "\n",
    "R2_df = pd.concat(R2_list).sort_index()\n",
    "R2_metrics = R2_df.groupby(R2_df.index).mean().round(2)\n",
    "\n",
    "Err = np.abs(df_predictions.groupby(df_predictions.index).mean()-Features)/Features\n",
    "       \n",
    "Err2 = Err.applymap(lambda x: \"{0:.1f}%\".format(x*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
